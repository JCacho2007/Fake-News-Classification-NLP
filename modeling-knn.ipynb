{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit Classification with Natural Language Processing\n",
    "\n",
    "## Modeling with $k$-Nearest Neighbors\n",
    "\n",
    "*Author: Grace Campbell*\n",
    "\n",
    "#### Project Directory\n",
    "1. Data Preparation \n",
    "    - [Data Gathering](http://localhost:8889/notebooks/projects/project_3/data-gathering.ipynb)\n",
    "    - [Exploratory Data Analysis](http://localhost:8889/notebooks/projects/project_3/exploratory-data-analysis.ipynb)\n",
    "2. Modeling\n",
    "    - [Naive Bayes](http://localhost:8889/notebooks/projects/project_3/modeling-naive-bayes.ipynb)\n",
    "    - *$k$-Nearest Neighbors*\n",
    "    - [Support-Vector Machine](http://localhost:8889/notebooks/projects/project_3/modeling-svm.ipynb)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Introduction\n",
    "\n",
    "In this notebook, I will be modeling with `KNeighborsClassifier`, which uses the $k$-Nearest Neighbors algorithm (a non-parametric method) to predict the class of a data point. The algorithm looks at the class membership of the $k$ closest neighbors to the query point; whichever class is the most represented among the neighbors is the class that gets predicted for the query point.  \n",
    "\n",
    "![image.png](attachment:image.png) [Image source](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#Algorithm)\n",
    "\n",
    "In the example above, the green dot is the query point. If $k$ is 3, then the majority class for the 3 nearest neighbors is 'red triangle', so the model will predict that class for the query point. If $k$ is 5, however, the majority class becomes 'blue square', so that is what the model will predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Strategy\n",
    "\n",
    "Before I can begin modeling, I need to turn my text data into numeric data using `TfidfVectorizer`. This transformer will create a matrix of values, where the columns represent every word that appears in the corpus, and the rows represent each document in the corpus. The values are TFIDF statistics for each word in a document.\n",
    "\n",
    "TFIDF stands for \"term frequency-inverse document frequency\" (**term frequency**: the number of times a word occurs in a document; **inverse document frequency**: an inverse function of the number of documents that contain the term). According to [Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), \"[t]he tfâ€“idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.\"\n",
    "\n",
    "Both of these methods have hyperparameters that can be tuned to optimize model performance, so I will perform a grid search using a pipeline with `TfidfVectorizer` and `KNeighborsClassifier` to find the best parameters for both in the context of one another. \n",
    "\n",
    "The grid search will test 3 different `TfidfVectorizer` hyperparameters:\n",
    "1. `max_features`: how many features to extract (chosen by highest total frequency)\n",
    "2. `min_df`: the minimum number of documents in which a feature must appear\n",
    "3. `max_df`: the maximum percentage of documents in which a feature can appear\n",
    "\n",
    "and 2 different `KNeighborsClassifier` hyperparameters:\n",
    "1. `n_neighbors`: the $k$ in $k$-Nearest Neighbors -- how many neighbors to compare a data point to in order to decide its class\n",
    "2. `weights`: the weight given to the neighbors (whether all are weighted equally or more weight is given to neighbors closer to the point in question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Searching for Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tokenizer import token_func\n",
    "\n",
    "df = pd.read_csv('./materials/titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and y\n",
    "X = df['title']\n",
    "y = df['is_onion']\n",
    "\n",
    "# Train-test splitting (with stratification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a pipeline\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(tokenizer=token_func)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Hyperparameters to search over\n",
    "params = {\n",
    "    'tvec__max_features': [None, 1000],\n",
    "    'tvec__min_df': [1, 2],\n",
    "    'tvec__max_df': [0.9, 1.0],\n",
    "    'knn__n_neighbors': [15, 25, 35],\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Fitting the grid search\n",
    "grid = GridSearchCV(pipe, params, cv=3)\n",
    "grid.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8037068239258636"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 15,\n",
       " 'knn__weights': 'distance',\n",
       " 'tvec__max_df': 0.9,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which parameters did the grid search choose?\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `TfidfVectorizer`, the grid search decided:   \n",
    "\n",
    "- `max_features` should be None\n",
    "    - I will have to investigate how many features are kept in the model when there is no maximum. I do not want many more features than I have rows in `X_train` (to prevent collinearity), so I may have to set the `max_features` anyway, regardless of this grid search result.\n",
    "\n",
    "\n",
    "- `min_df` should be 1, effectively meaning there is no minimum document frequency\n",
    "    - Again, I need to see how many features the model keeps, and may need to change `min_df` anyway.\n",
    "\n",
    "\n",
    "- `max_df` should be 0.9, meaning a feature will not be included in the model if it appears in more than 90% of the documents\n",
    "    - Since I eliminated stopwords from the tokens, there most likely will not be many (if any) words that show up in more than 90% of the titles.\n",
    "    \n",
    "    \n",
    "For `KNeighborsClassifier`, the grid search decided:\n",
    "\n",
    "- `n_neighbors` should be 15\n",
    "    - The 15 neighbors closest to the query point will be considered. I believe that 15 neighbors is a number that results in a good bias-variance trade-off: it is small enough that the bias is relatively low, but not so small that the variance is extremely high.\n",
    "    \n",
    "\n",
    "- `weights` should be `distance`\n",
    "    - The closer a neighbor is to the query point, the more influence that point will have over the class prediction. Neighbors that are farther away will have less influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming `X` Using Best Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I suspected, there are almost 3 times more features in `X_train` than there are rows when `max_features` is None and `min_df` is only 1. After some adjustments, I found setting `max_features` to 2000 still results in a good score while not having too many more features than there are observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(tokenizer=token_func, max_features=2000, min_df=1, max_df=0.9)\n",
    "\n",
    "tvec.fit(X_train)\n",
    "\n",
    "X_train_t = pd.DataFrame(tvec.transform(X_train).todense(), columns=tvec.get_feature_names())\n",
    "X_test_t  = pd.DataFrame(tvec.transform(X_test).todense(), columns=tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating and fitting the model\n",
    "knn = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "knn.fit(X_train_t, y_train)\n",
    "\n",
    "# Storing predictions\n",
    "y_pred = knn.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156565656565656"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score\n",
    "knn.score(X_test_t, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 224\n",
      "False Negatives: 13\n",
      "True Negatives: 99\n",
      "False Positives: 60\n",
      "\n",
      "Sensitivity: 0.9451476793248945\n",
      "Specificity: 0.6226415094339622\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix + other metrics\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f'True Positives: {tp}')\n",
    "print(f'False Negatives: {fn}')\n",
    "print(f'True Negatives: {tn}')\n",
    "print(f'False Positives: {fp}\\n')\n",
    "print(f'Sensitivity: {tp/(tp+fn)}')\n",
    "print(f'Specificity: {tn/(tn+fp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy score for the data is the score I would get if I predicted the majority class for every data point. The majority class here, /r/TheOnion, holds around 60% of the data. If I were to predict that every document in the data belonged to /r/TheOnion, I would get an accuracy score of 60%. That is to say, if a model does not predict subreddit membership with greater than 60% accuracy, then it is not a very good model.\n",
    "\n",
    "The fewer features in this model, the poorer its performance. When its `max_features` was None, the model had ~4000 features and scored around 84%, meaning that the model correctly predicted the class 84% of the time. After reducing the `max_features` to 2000, the accuracy score dropped slightly to 82%. When `max_features` was dropped to the number of rows, 1187, the accuracy score dropped further, to around 70%. To get the highest possible accuracy score from this model, I would need to gather more data so that the model could use more features to make predictions.\n",
    "\n",
    "The model has very high sensitivity, meaning that almost all of the posts that were actually from /r/TheOnion were correctly predicted to be from /r/TheOnion. On the flip side, the model has much lower specificity, which means that only about 62% of posts that belong to /r/News were correctly predicted to be from /r/News. It seems that this model is content to predict the positive class almost every time. \n",
    "\n",
    "In a real-world application, it is equally important to me that this model be able to correctly predict when a post is satirical **and** when it is real. The positive class in this case is does not hold more weight than the negative class, therefore I would rather the model be very accurate than very sensitive. For this reason, I do not believe $k$-Nearest Neighbors, at least not this iteration, is the best model for my purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
